{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d7adf099",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import neurokit2 as nk\n",
    "import json\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.model_selection import LeaveOneOut, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_selection import RFECV, RFE\n",
    "\n",
    "from Participant import Participant\n",
    "from feature_extraction import skt_features\n",
    "from helper import extract_segments, extract_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a87cb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Initialize participant IDs\n",
    "all_participant_ids = np.arange(1, 46)\n",
    "# remove participant 5 due to tehcnical issues (incomplete experiment)\n",
    "all_participant_ids = all_participant_ids[all_participant_ids != 5]\n",
    "# remove participant 28 due to missing timestamps\n",
    "all_participant_ids = all_participant_ids[all_participant_ids != 28]\n",
    "# remove participant 19 due to technical issues (problematic physiological data)\n",
    "all_participant_ids = all_participant_ids[all_participant_ids != 19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07f45449",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "443f321c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Window parameters: Signal to Features\n",
    "delta_start = -5\n",
    "duration = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bc6906c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUCCESS 1: All conditions have 54 segments.\n",
      "SUCCESS 2: All conditions have 54 segments.\n",
      "SUCCESS 3: All conditions have 54 segments.\n",
      "SUCCESS 4: All conditions have 54 segments.\n",
      "SUCCESS 6: All conditions have 54 segments.\n",
      "SUCCESS 7: All conditions have 54 segments.\n",
      "SUCCESS 8: All conditions have 54 segments.\n",
      "SUCCESS 9: All conditions have 54 segments.\n",
      "SUCCESS 10: All conditions have 54 segments.\n",
      "SUCCESS 11: All conditions have 54 segments.\n",
      "SUCCESS 12: All conditions have 54 segments.\n",
      "SUCCESS 13: All conditions have 54 segments.\n",
      "SUCCESS 14: All conditions have 54 segments.\n",
      "SUCCESS 15: All conditions have 54 segments.\n",
      "SUCCESS 16: All conditions have 54 segments.\n",
      "SUCCESS 17: All conditions have 54 segments.\n",
      "SUCCESS 18: All conditions have 54 segments.\n",
      "SUCCESS 20: All conditions have 54 segments.\n",
      "SUCCESS 21: All conditions have 54 segments.\n",
      "SUCCESS 22: All conditions have 54 segments.\n",
      "SUCCESS 23: All conditions have 54 segments.\n",
      "SUCCESS 24: All conditions have 54 segments.\n",
      "SUCCESS 25: All conditions have 54 segments.\n",
      "SUCCESS 26: All conditions have 54 segments.\n",
      "SUCCESS 27: All conditions have 54 segments.\n",
      "SUCCESS 29: All conditions have 54 segments.\n",
      "SUCCESS 30: All conditions have 54 segments.\n",
      "SUCCESS 31: All conditions have 54 segments.\n",
      "SUCCESS 32: All conditions have 54 segments.\n",
      "SUCCESS 33: All conditions have 54 segments.\n",
      "SUCCESS 34: All conditions have 54 segments.\n",
      "SUCCESS 35: All conditions have 54 segments.\n",
      "SUCCESS 36: All conditions have 54 segments.\n",
      "SUCCESS 37: All conditions have 54 segments.\n",
      "SUCCESS 38: All conditions have 54 segments.\n",
      "SUCCESS 39: All conditions have 54 segments.\n",
      "SUCCESS 40: All conditions have 54 segments.\n",
      "SUCCESS 41: All conditions have 54 segments.\n",
      "SUCCESS 42: All conditions have 54 segments.\n",
      "SUCCESS 43: All conditions have 54 segments.\n",
      "SUCCESS 44: All conditions have 54 segments.\n",
      "SUCCESS 45: All conditions have 54 segments.\n",
      "\n",
      "==================================================\n",
      "--- Global Segment Length Report ---\n",
      "Minimal IBI segment length found: 19\n",
      "Minimal EDA segment length found: 96\n",
      "Minimal SKT segment length found: 23\n"
     ]
    }
   ],
   "source": [
    "# ADDED: Global trackers for minimal segment lengths across all participants\n",
    "global_min_ibi_len = float('inf')\n",
    "global_min_eda_len = float('inf')\n",
    "global_min_skt_len = float('inf')\n",
    "\n",
    "for pid in all_participant_ids:\n",
    "    ### Initialize storage for participant-sepcific information \n",
    "    p = Participant(participantID=pid, rawData=True)\n",
    "        \n",
    "    # Store counts per condition *for this participant*\n",
    "    condition_segment_counts = {} \n",
    "        \n",
    "    for condition in {'audio+image', 'image-only', 'audio-only'}:\n",
    "        ### Initialize storage for feature matrix and labels\n",
    "        X = []\n",
    "        y = []\n",
    "\n",
    "        ### Storage for segments of each physiological signal\n",
    "        ### Lists of dictionaries\n",
    "        ibi_segments = []\n",
    "        eda_segments = []\n",
    "        skt_segments = []\n",
    "\n",
    "        ### Iterate over blocks of the specified condition\n",
    "        condition_mask = p.markers['condition'] == condition\n",
    "        ## Drop one random sample of each target emotion for 'audio-only' condition\n",
    "        if condition == 'audio-only':\n",
    "            audio_only_df = p.markers[p.markers['condition'] == 'audio-only'].copy()\n",
    "            target_emotions = ['Happiness', 'Anger', 'Sadness']\n",
    "            filtered_audio_only_df = audio_only_df[audio_only_df['target_emotion'].isin(target_emotions)] \n",
    "            try:\n",
    "                sampled_rows = filtered_audio_only_df.groupby('target_emotion').sample(n=1, random_state=42)\n",
    "                remaining_rows = audio_only_df.drop(sampled_rows.index)\n",
    "            except ValueError:\n",
    "                remaining_rows = audio_only_df # If sampling fails, use all rows\n",
    "        else:\n",
    "            remaining_rows = p.markers[condition_mask]\n",
    "            \n",
    "        for block_index in remaining_rows.index:\n",
    "\n",
    "            ### Get onsets depending on condition\n",
    "            if condition == 'audio-only':\n",
    "                audio_onset = p.markers['audio_onset'].iloc[block_index]\n",
    "                # 60 second trials with 10 second intervals between segments\n",
    "                # Intervals have the same duration as an image presentation\n",
    "                onsets = np.arange(audio_onset, audio_onset + 60000, 10000)\n",
    "            else:\n",
    "                onsets = json.loads(p.markers.iloc[block_index]['image_onsets'])\n",
    "\n",
    "            ### Extract segments for each onset\n",
    "            for onset in onsets:\n",
    "                timestamp = onset / 1000  # Convert milliseconds to seconds\n",
    "                segment = p.get_rawData_from_timestamp(timestamp, delta_start, duration)\n",
    "                ibi_segments.append(segment['systolicPeaks'])\n",
    "                eda_segments.append(segment['eda'])\n",
    "                skt_segments.append(segment['skt'])\n",
    "                y.append(p.markers.loc[block_index, 'target_emotion'])\n",
    "\n",
    "        # --- ADDED: NEW ASSERTION 1 (Segments are not empty) & MIN LENGTH UPDATE ---\n",
    "        # Only run if segments were actually collected\n",
    "        if y: # Checks if list is not empty\n",
    "            assert all(len(s) > 0 for s in ibi_segments), f\"Found empty IBI segment for {pid} ({condition})\"\n",
    "            assert all(len(s) > 0 for s in eda_segments), f\"Found empty EDA segment for {pid} ({condition})\"\n",
    "            assert all(len(s) > 0 for s in skt_segments), f\"Found empty SKT segment for {pid} ({condition})\"\n",
    "            \n",
    "            # Update global minimums\n",
    "            global_min_ibi_len = min(global_min_ibi_len, min(len(s) for s in ibi_segments))\n",
    "            global_min_eda_len = min(global_min_eda_len, min(len(s) for s in eda_segments))\n",
    "            global_min_skt_len = min(global_min_skt_len, min(len(s) for s in skt_segments))\n",
    "\n",
    "        # --- EXISTING: ASSERTION 2 (Internal Consistency) ---\n",
    "        n_segments = len(y)\n",
    "        assert len(ibi_segments) == n_segments and len(eda_segments) == n_segments and len(skt_segments) == n_segments, \\\n",
    "            f\"Data mismatch for {pid} ({condition}): y={n_segments}, ibi={len(ibi_segments)}, eda={len(eda_segments)}, skt={len(skt_segments)}\"\n",
    "        \n",
    "        # Store count for this condition (for Assertion 3)\n",
    "        condition_segment_counts[condition] = n_segments\n",
    "    \n",
    "    # --- EXISTING: ASSERTION 3 (Cross-Condition Consistency for this Participant) ---\n",
    "    counts = list(condition_segment_counts.values())\n",
    "    assert len(counts) == 3 and all(c == counts[0] for c in counts), \\\n",
    "        f\"FAIL {pid}: Mismatch in segment counts across conditions: {condition_segment_counts}\"\n",
    "    print(f\"SUCCESS {pid}: All conditions have {counts[0]} segments.\")\n",
    "\n",
    "# --- ADDED: Final Print of Global Mins ---\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"--- Global Segment Length Report ---\")\n",
    "print(f\"Minimal IBI segment length found: {global_min_ibi_len if global_min_ibi_len != float('inf') else 'N/A'}\")\n",
    "print(f\"Minimal EDA segment length found: {global_min_eda_len if global_min_eda_len != float('inf') else 'N/A'}\")\n",
    "print(f\"Minimal SKT segment length found: {global_min_skt_len if global_min_skt_len != float('inf') else 'N/A'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "fee24693",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\eda\\eda_clean.py:105: NeuroKitWarning: EDA signal is sampled at very low frequency. Skipping filtering.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\epochs\\eventrelated_utils.py:37: NeuroKitWarning: eda_eventrelated(): The duration of your epochs seems quite long. You might want to use eda_intervalrelated().\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\eda\\eda_clean.py:105: NeuroKitWarning: EDA signal is sampled at very low frequency. Skipping filtering.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\epochs\\eventrelated_utils.py:37: NeuroKitWarning: eda_eventrelated(): The duration of your epochs seems quite long. You might want to use eda_intervalrelated().\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\hrv\\hrv_nonlinear.py:529: NeuroKitWarning: DFA_alpha2 related indices will not be calculated. The maximum duration of the windows provided for the long-term correlation is smaller than the minimum duration of windows. Refer to the `scale` argument in `nk.fractal_dfa()` for more information.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\eda\\eda_clean.py:105: NeuroKitWarning: EDA signal is sampled at very low frequency. Skipping filtering.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\epochs\\eventrelated_utils.py:37: NeuroKitWarning: eda_eventrelated(): The duration of your epochs seems quite long. You might want to use eda_intervalrelated().\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\eda\\eda_clean.py:105: NeuroKitWarning: EDA signal is sampled at very low frequency. Skipping filtering.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\epochs\\eventrelated_utils.py:37: NeuroKitWarning: eda_eventrelated(): The duration of your epochs seems quite long. You might want to use eda_intervalrelated().\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\hrv\\hrv_nonlinear.py:529: NeuroKitWarning: DFA_alpha2 related indices will not be calculated. The maximum duration of the windows provided for the long-term correlation is smaller than the minimum duration of windows. Refer to the `scale` argument in `nk.fractal_dfa()` for more information.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\eda\\eda_clean.py:105: NeuroKitWarning: EDA signal is sampled at very low frequency. Skipping filtering.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\epochs\\eventrelated_utils.py:37: NeuroKitWarning: eda_eventrelated(): The duration of your epochs seems quite long. You might want to use eda_intervalrelated().\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\eda\\eda_clean.py:105: NeuroKitWarning: EDA signal is sampled at very low frequency. Skipping filtering.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\epochs\\eventrelated_utils.py:37: NeuroKitWarning: eda_eventrelated(): The duration of your epochs seems quite long. You might want to use eda_intervalrelated().\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\hrv\\hrv_nonlinear.py:529: NeuroKitWarning: DFA_alpha2 related indices will not be calculated. The maximum duration of the windows provided for the long-term correlation is smaller than the minimum duration of windows. Refer to the `scale` argument in `nk.fractal_dfa()` for more information.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\complexity\\entropy_multiscale.py:349: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  mse = np.trapz(mse) / len(mse)\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\complexity\\entropy_multiscale.py:349: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  mse = np.trapz(mse) / len(mse)\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\complexity\\entropy_multiscale.py:349: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  mse = np.trapz(mse) / len(mse)\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\eda\\eda_clean.py:105: NeuroKitWarning: EDA signal is sampled at very low frequency. Skipping filtering.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\epochs\\eventrelated_utils.py:37: NeuroKitWarning: eda_eventrelated(): The duration of your epochs seems quite long. You might want to use eda_intervalrelated().\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\eda\\eda_clean.py:105: NeuroKitWarning: EDA signal is sampled at very low frequency. Skipping filtering.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\epochs\\eventrelated_utils.py:37: NeuroKitWarning: eda_eventrelated(): The duration of your epochs seems quite long. You might want to use eda_intervalrelated().\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\hrv\\hrv_nonlinear.py:529: NeuroKitWarning: DFA_alpha2 related indices will not be calculated. The maximum duration of the windows provided for the long-term correlation is smaller than the minimum duration of windows. Refer to the `scale` argument in `nk.fractal_dfa()` for more information.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\eda\\eda_clean.py:105: NeuroKitWarning: EDA signal is sampled at very low frequency. Skipping filtering.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\epochs\\eventrelated_utils.py:37: NeuroKitWarning: eda_eventrelated(): The duration of your epochs seems quite long. You might want to use eda_intervalrelated().\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\eda\\eda_clean.py:105: NeuroKitWarning: EDA signal is sampled at very low frequency. Skipping filtering.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\epochs\\eventrelated_utils.py:37: NeuroKitWarning: eda_eventrelated(): The duration of your epochs seems quite long. You might want to use eda_intervalrelated().\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\hrv\\hrv_nonlinear.py:529: NeuroKitWarning: DFA_alpha2 related indices will not be calculated. The maximum duration of the windows provided for the long-term correlation is smaller than the minimum duration of windows. Refer to the `scale` argument in `nk.fractal_dfa()` for more information.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\complexity\\entropy_multiscale.py:349: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  mse = np.trapz(mse) / len(mse)\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\complexity\\entropy_multiscale.py:349: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  mse = np.trapz(mse) / len(mse)\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\complexity\\entropy_multiscale.py:349: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  mse = np.trapz(mse) / len(mse)\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\eda\\eda_clean.py:105: NeuroKitWarning: EDA signal is sampled at very low frequency. Skipping filtering.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\epochs\\eventrelated_utils.py:37: NeuroKitWarning: eda_eventrelated(): The duration of your epochs seems quite long. You might want to use eda_intervalrelated().\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\eda\\eda_clean.py:105: NeuroKitWarning: EDA signal is sampled at very low frequency. Skipping filtering.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\epochs\\eventrelated_utils.py:37: NeuroKitWarning: eda_eventrelated(): The duration of your epochs seems quite long. You might want to use eda_intervalrelated().\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\hrv\\hrv_nonlinear.py:529: NeuroKitWarning: DFA_alpha2 related indices will not be calculated. The maximum duration of the windows provided for the long-term correlation is smaller than the minimum duration of windows. Refer to the `scale` argument in `nk.fractal_dfa()` for more information.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\complexity\\entropy_multiscale.py:349: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  mse = np.trapz(mse) / len(mse)\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\complexity\\entropy_multiscale.py:349: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  mse = np.trapz(mse) / len(mse)\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\complexity\\entropy_multiscale.py:349: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  mse = np.trapz(mse) / len(mse)\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\eda\\eda_clean.py:105: NeuroKitWarning: EDA signal is sampled at very low frequency. Skipping filtering.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\epochs\\eventrelated_utils.py:37: NeuroKitWarning: eda_eventrelated(): The duration of your epochs seems quite long. You might want to use eda_intervalrelated().\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\eda\\eda_clean.py:105: NeuroKitWarning: EDA signal is sampled at very low frequency. Skipping filtering.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\epochs\\eventrelated_utils.py:37: NeuroKitWarning: eda_eventrelated(): The duration of your epochs seems quite long. You might want to use eda_intervalrelated().\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\hrv\\hrv_nonlinear.py:529: NeuroKitWarning: DFA_alpha2 related indices will not be calculated. The maximum duration of the windows provided for the long-term correlation is smaller than the minimum duration of windows. Refer to the `scale` argument in `nk.fractal_dfa()` for more information.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\eda\\eda_clean.py:105: NeuroKitWarning: EDA signal is sampled at very low frequency. Skipping filtering.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\epochs\\eventrelated_utils.py:37: NeuroKitWarning: eda_eventrelated(): The duration of your epochs seems quite long. You might want to use eda_intervalrelated().\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\eda\\eda_clean.py:105: NeuroKitWarning: EDA signal is sampled at very low frequency. Skipping filtering.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\epochs\\eventrelated_utils.py:37: NeuroKitWarning: eda_eventrelated(): The duration of your epochs seems quite long. You might want to use eda_intervalrelated().\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\hrv\\hrv_nonlinear.py:529: NeuroKitWarning: DFA_alpha2 related indices will not be calculated. The maximum duration of the windows provided for the long-term correlation is smaller than the minimum duration of windows. Refer to the `scale` argument in `nk.fractal_dfa()` for more information.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\eda\\eda_clean.py:105: NeuroKitWarning: EDA signal is sampled at very low frequency. Skipping filtering.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\epochs\\eventrelated_utils.py:37: NeuroKitWarning: eda_eventrelated(): The duration of your epochs seems quite long. You might want to use eda_intervalrelated().\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\eda\\eda_clean.py:105: NeuroKitWarning: EDA signal is sampled at very low frequency. Skipping filtering.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\epochs\\eventrelated_utils.py:37: NeuroKitWarning: eda_eventrelated(): The duration of your epochs seems quite long. You might want to use eda_intervalrelated().\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\hrv\\hrv_nonlinear.py:529: NeuroKitWarning: DFA_alpha2 related indices will not be calculated. The maximum duration of the windows provided for the long-term correlation is smaller than the minimum duration of windows. Refer to the `scale` argument in `nk.fractal_dfa()` for more information.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\complexity\\entropy_multiscale.py:349: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  mse = np.trapz(mse) / len(mse)\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\complexity\\entropy_multiscale.py:349: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  mse = np.trapz(mse) / len(mse)\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\complexity\\entropy_multiscale.py:349: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  mse = np.trapz(mse) / len(mse)\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\eda\\eda_clean.py:105: NeuroKitWarning: EDA signal is sampled at very low frequency. Skipping filtering.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\epochs\\eventrelated_utils.py:37: NeuroKitWarning: eda_eventrelated(): The duration of your epochs seems quite long. You might want to use eda_intervalrelated().\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\eda\\eda_clean.py:105: NeuroKitWarning: EDA signal is sampled at very low frequency. Skipping filtering.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\epochs\\eventrelated_utils.py:37: NeuroKitWarning: eda_eventrelated(): The duration of your epochs seems quite long. You might want to use eda_intervalrelated().\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\hrv\\hrv_nonlinear.py:529: NeuroKitWarning: DFA_alpha2 related indices will not be calculated. The maximum duration of the windows provided for the long-term correlation is smaller than the minimum duration of windows. Refer to the `scale` argument in `nk.fractal_dfa()` for more information.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\complexity\\entropy_multiscale.py:349: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  mse = np.trapz(mse) / len(mse)\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\complexity\\entropy_multiscale.py:349: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  mse = np.trapz(mse) / len(mse)\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\complexity\\entropy_multiscale.py:349: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  mse = np.trapz(mse) / len(mse)\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\eda\\eda_clean.py:105: NeuroKitWarning: EDA signal is sampled at very low frequency. Skipping filtering.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\epochs\\eventrelated_utils.py:37: NeuroKitWarning: eda_eventrelated(): The duration of your epochs seems quite long. You might want to use eda_intervalrelated().\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\eda\\eda_clean.py:105: NeuroKitWarning: EDA signal is sampled at very low frequency. Skipping filtering.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\epochs\\eventrelated_utils.py:37: NeuroKitWarning: eda_eventrelated(): The duration of your epochs seems quite long. You might want to use eda_intervalrelated().\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\hrv\\hrv_nonlinear.py:529: NeuroKitWarning: DFA_alpha2 related indices will not be calculated. The maximum duration of the windows provided for the long-term correlation is smaller than the minimum duration of windows. Refer to the `scale` argument in `nk.fractal_dfa()` for more information.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\eda\\eda_clean.py:105: NeuroKitWarning: EDA signal is sampled at very low frequency. Skipping filtering.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\epochs\\eventrelated_utils.py:37: NeuroKitWarning: eda_eventrelated(): The duration of your epochs seems quite long. You might want to use eda_intervalrelated().\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\eda\\eda_clean.py:105: NeuroKitWarning: EDA signal is sampled at very low frequency. Skipping filtering.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\epochs\\eventrelated_utils.py:37: NeuroKitWarning: eda_eventrelated(): The duration of your epochs seems quite long. You might want to use eda_intervalrelated().\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\hrv\\hrv_nonlinear.py:529: NeuroKitWarning: DFA_alpha2 related indices will not be calculated. The maximum duration of the windows provided for the long-term correlation is smaller than the minimum duration of windows. Refer to the `scale` argument in `nk.fractal_dfa()` for more information.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\complexity\\entropy_multiscale.py:349: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  mse = np.trapz(mse) / len(mse)\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\complexity\\entropy_multiscale.py:349: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  mse = np.trapz(mse) / len(mse)\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\complexity\\entropy_multiscale.py:349: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  mse = np.trapz(mse) / len(mse)\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\eda\\eda_clean.py:105: NeuroKitWarning: EDA signal is sampled at very low frequency. Skipping filtering.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\epochs\\eventrelated_utils.py:37: NeuroKitWarning: eda_eventrelated(): The duration of your epochs seems quite long. You might want to use eda_intervalrelated().\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\eda\\eda_clean.py:105: NeuroKitWarning: EDA signal is sampled at very low frequency. Skipping filtering.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\epochs\\eventrelated_utils.py:37: NeuroKitWarning: eda_eventrelated(): The duration of your epochs seems quite long. You might want to use eda_intervalrelated().\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\hrv\\hrv_nonlinear.py:529: NeuroKitWarning: DFA_alpha2 related indices will not be calculated. The maximum duration of the windows provided for the long-term correlation is smaller than the minimum duration of windows. Refer to the `scale` argument in `nk.fractal_dfa()` for more information.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\eda\\eda_clean.py:105: NeuroKitWarning: EDA signal is sampled at very low frequency. Skipping filtering.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\epochs\\eventrelated_utils.py:37: NeuroKitWarning: eda_eventrelated(): The duration of your epochs seems quite long. You might want to use eda_intervalrelated().\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\eda\\eda_clean.py:105: NeuroKitWarning: EDA signal is sampled at very low frequency. Skipping filtering.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\epochs\\eventrelated_utils.py:37: NeuroKitWarning: eda_eventrelated(): The duration of your epochs seems quite long. You might want to use eda_intervalrelated().\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\hrv\\hrv_nonlinear.py:529: NeuroKitWarning: DFA_alpha2 related indices will not be calculated. The maximum duration of the windows provided for the long-term correlation is smaller than the minimum duration of windows. Refer to the `scale` argument in `nk.fractal_dfa()` for more information.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\eda\\eda_clean.py:105: NeuroKitWarning: EDA signal is sampled at very low frequency. Skipping filtering.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\epochs\\eventrelated_utils.py:37: NeuroKitWarning: eda_eventrelated(): The duration of your epochs seems quite long. You might want to use eda_intervalrelated().\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\eda\\eda_clean.py:105: NeuroKitWarning: EDA signal is sampled at very low frequency. Skipping filtering.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\epochs\\eventrelated_utils.py:37: NeuroKitWarning: eda_eventrelated(): The duration of your epochs seems quite long. You might want to use eda_intervalrelated().\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\hrv\\hrv_nonlinear.py:529: NeuroKitWarning: DFA_alpha2 related indices will not be calculated. The maximum duration of the windows provided for the long-term correlation is smaller than the minimum duration of windows. Refer to the `scale` argument in `nk.fractal_dfa()` for more information.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\eda\\eda_clean.py:105: NeuroKitWarning: EDA signal is sampled at very low frequency. Skipping filtering.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\epochs\\eventrelated_utils.py:37: NeuroKitWarning: eda_eventrelated(): The duration of your epochs seems quite long. You might want to use eda_intervalrelated().\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\eda\\eda_clean.py:105: NeuroKitWarning: EDA signal is sampled at very low frequency. Skipping filtering.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\epochs\\eventrelated_utils.py:37: NeuroKitWarning: eda_eventrelated(): The duration of your epochs seems quite long. You might want to use eda_intervalrelated().\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\hrv\\hrv_nonlinear.py:529: NeuroKitWarning: DFA_alpha2 related indices will not be calculated. The maximum duration of the windows provided for the long-term correlation is smaller than the minimum duration of windows. Refer to the `scale` argument in `nk.fractal_dfa()` for more information.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\eda\\eda_clean.py:105: NeuroKitWarning: EDA signal is sampled at very low frequency. Skipping filtering.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\epochs\\eventrelated_utils.py:37: NeuroKitWarning: eda_eventrelated(): The duration of your epochs seems quite long. You might want to use eda_intervalrelated().\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\eda\\eda_clean.py:105: NeuroKitWarning: EDA signal is sampled at very low frequency. Skipping filtering.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\epochs\\eventrelated_utils.py:37: NeuroKitWarning: eda_eventrelated(): The duration of your epochs seems quite long. You might want to use eda_intervalrelated().\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\hrv\\hrv_nonlinear.py:529: NeuroKitWarning: DFA_alpha2 related indices will not be calculated. The maximum duration of the windows provided for the long-term correlation is smaller than the minimum duration of windows. Refer to the `scale` argument in `nk.fractal_dfa()` for more information.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\complexity\\entropy_multiscale.py:349: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  mse = np.trapz(mse) / len(mse)\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\complexity\\entropy_multiscale.py:349: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  mse = np.trapz(mse) / len(mse)\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\complexity\\entropy_multiscale.py:349: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  mse = np.trapz(mse) / len(mse)\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\eda\\eda_clean.py:105: NeuroKitWarning: EDA signal is sampled at very low frequency. Skipping filtering.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\epochs\\eventrelated_utils.py:37: NeuroKitWarning: eda_eventrelated(): The duration of your epochs seems quite long. You might want to use eda_intervalrelated().\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\eda\\eda_clean.py:105: NeuroKitWarning: EDA signal is sampled at very low frequency. Skipping filtering.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\epochs\\eventrelated_utils.py:37: NeuroKitWarning: eda_eventrelated(): The duration of your epochs seems quite long. You might want to use eda_intervalrelated().\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\hrv\\hrv_nonlinear.py:529: NeuroKitWarning: DFA_alpha2 related indices will not be calculated. The maximum duration of the windows provided for the long-term correlation is smaller than the minimum duration of windows. Refer to the `scale` argument in `nk.fractal_dfa()` for more information.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\complexity\\entropy_multiscale.py:349: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  mse = np.trapz(mse) / len(mse)\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\complexity\\entropy_multiscale.py:349: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  mse = np.trapz(mse) / len(mse)\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\complexity\\entropy_multiscale.py:349: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  mse = np.trapz(mse) / len(mse)\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\eda\\eda_clean.py:105: NeuroKitWarning: EDA signal is sampled at very low frequency. Skipping filtering.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\epochs\\eventrelated_utils.py:37: NeuroKitWarning: eda_eventrelated(): The duration of your epochs seems quite long. You might want to use eda_intervalrelated().\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\eda\\eda_clean.py:105: NeuroKitWarning: EDA signal is sampled at very low frequency. Skipping filtering.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\epochs\\eventrelated_utils.py:37: NeuroKitWarning: eda_eventrelated(): The duration of your epochs seems quite long. You might want to use eda_intervalrelated().\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\hrv\\hrv_nonlinear.py:529: NeuroKitWarning: DFA_alpha2 related indices will not be calculated. The maximum duration of the windows provided for the long-term correlation is smaller than the minimum duration of windows. Refer to the `scale` argument in `nk.fractal_dfa()` for more information.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\eda\\eda_clean.py:105: NeuroKitWarning: EDA signal is sampled at very low frequency. Skipping filtering.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\epochs\\eventrelated_utils.py:37: NeuroKitWarning: eda_eventrelated(): The duration of your epochs seems quite long. You might want to use eda_intervalrelated().\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\eda\\eda_clean.py:105: NeuroKitWarning: EDA signal is sampled at very low frequency. Skipping filtering.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\epochs\\eventrelated_utils.py:37: NeuroKitWarning: eda_eventrelated(): The duration of your epochs seems quite long. You might want to use eda_intervalrelated().\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\hrv\\hrv_nonlinear.py:529: NeuroKitWarning: DFA_alpha2 related indices will not be calculated. The maximum duration of the windows provided for the long-term correlation is smaller than the minimum duration of windows. Refer to the `scale` argument in `nk.fractal_dfa()` for more information.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\eda\\eda_clean.py:105: NeuroKitWarning: EDA signal is sampled at very low frequency. Skipping filtering.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\epochs\\eventrelated_utils.py:37: NeuroKitWarning: eda_eventrelated(): The duration of your epochs seems quite long. You might want to use eda_intervalrelated().\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\eda\\eda_clean.py:105: NeuroKitWarning: EDA signal is sampled at very low frequency. Skipping filtering.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\epochs\\eventrelated_utils.py:37: NeuroKitWarning: eda_eventrelated(): The duration of your epochs seems quite long. You might want to use eda_intervalrelated().\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\hrv\\hrv_nonlinear.py:529: NeuroKitWarning: DFA_alpha2 related indices will not be calculated. The maximum duration of the windows provided for the long-term correlation is smaller than the minimum duration of windows. Refer to the `scale` argument in `nk.fractal_dfa()` for more information.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\eda\\eda_clean.py:105: NeuroKitWarning: EDA signal is sampled at very low frequency. Skipping filtering.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\epochs\\eventrelated_utils.py:37: NeuroKitWarning: eda_eventrelated(): The duration of your epochs seems quite long. You might want to use eda_intervalrelated().\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\eda\\eda_clean.py:105: NeuroKitWarning: EDA signal is sampled at very low frequency. Skipping filtering.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\epochs\\eventrelated_utils.py:37: NeuroKitWarning: eda_eventrelated(): The duration of your epochs seems quite long. You might want to use eda_intervalrelated().\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\hrv\\hrv_nonlinear.py:529: NeuroKitWarning: DFA_alpha2 related indices will not be calculated. The maximum duration of the windows provided for the long-term correlation is smaller than the minimum duration of windows. Refer to the `scale` argument in `nk.fractal_dfa()` for more information.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\eda\\eda_clean.py:105: NeuroKitWarning: EDA signal is sampled at very low frequency. Skipping filtering.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\epochs\\eventrelated_utils.py:37: NeuroKitWarning: eda_eventrelated(): The duration of your epochs seems quite long. You might want to use eda_intervalrelated().\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\eda\\eda_clean.py:105: NeuroKitWarning: EDA signal is sampled at very low frequency. Skipping filtering.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\epochs\\eventrelated_utils.py:37: NeuroKitWarning: eda_eventrelated(): The duration of your epochs seems quite long. You might want to use eda_intervalrelated().\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\hrv\\hrv_nonlinear.py:529: NeuroKitWarning: DFA_alpha2 related indices will not be calculated. The maximum duration of the windows provided for the long-term correlation is smaller than the minimum duration of windows. Refer to the `scale` argument in `nk.fractal_dfa()` for more information.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\complexity\\entropy_multiscale.py:349: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  mse = np.trapz(mse) / len(mse)\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\complexity\\entropy_multiscale.py:349: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  mse = np.trapz(mse) / len(mse)\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\complexity\\entropy_multiscale.py:349: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  mse = np.trapz(mse) / len(mse)\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\eda\\eda_clean.py:105: NeuroKitWarning: EDA signal is sampled at very low frequency. Skipping filtering.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\epochs\\eventrelated_utils.py:37: NeuroKitWarning: eda_eventrelated(): The duration of your epochs seems quite long. You might want to use eda_intervalrelated().\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\eda\\eda_clean.py:105: NeuroKitWarning: EDA signal is sampled at very low frequency. Skipping filtering.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\epochs\\eventrelated_utils.py:37: NeuroKitWarning: eda_eventrelated(): The duration of your epochs seems quite long. You might want to use eda_intervalrelated().\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\hrv\\hrv_nonlinear.py:529: NeuroKitWarning: DFA_alpha2 related indices will not be calculated. The maximum duration of the windows provided for the long-term correlation is smaller than the minimum duration of windows. Refer to the `scale` argument in `nk.fractal_dfa()` for more information.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\complexity\\entropy_multiscale.py:349: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  mse = np.trapz(mse) / len(mse)\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\complexity\\entropy_multiscale.py:349: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  mse = np.trapz(mse) / len(mse)\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\complexity\\entropy_multiscale.py:349: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  mse = np.trapz(mse) / len(mse)\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\eda\\eda_clean.py:105: NeuroKitWarning: EDA signal is sampled at very low frequency. Skipping filtering.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\epochs\\eventrelated_utils.py:37: NeuroKitWarning: eda_eventrelated(): The duration of your epochs seems quite long. You might want to use eda_intervalrelated().\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\eda\\eda_clean.py:105: NeuroKitWarning: EDA signal is sampled at very low frequency. Skipping filtering.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\epochs\\eventrelated_utils.py:37: NeuroKitWarning: eda_eventrelated(): The duration of your epochs seems quite long. You might want to use eda_intervalrelated().\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\hrv\\hrv_nonlinear.py:529: NeuroKitWarning: DFA_alpha2 related indices will not be calculated. The maximum duration of the windows provided for the long-term correlation is smaller than the minimum duration of windows. Refer to the `scale` argument in `nk.fractal_dfa()` for more information.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\eda\\eda_clean.py:105: NeuroKitWarning: EDA signal is sampled at very low frequency. Skipping filtering.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\epochs\\eventrelated_utils.py:37: NeuroKitWarning: eda_eventrelated(): The duration of your epochs seems quite long. You might want to use eda_intervalrelated().\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\eda\\eda_clean.py:105: NeuroKitWarning: EDA signal is sampled at very low frequency. Skipping filtering.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\epochs\\eventrelated_utils.py:37: NeuroKitWarning: eda_eventrelated(): The duration of your epochs seems quite long. You might want to use eda_intervalrelated().\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\hrv\\hrv_nonlinear.py:529: NeuroKitWarning: DFA_alpha2 related indices will not be calculated. The maximum duration of the windows provided for the long-term correlation is smaller than the minimum duration of windows. Refer to the `scale` argument in `nk.fractal_dfa()` for more information.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\eda\\eda_clean.py:105: NeuroKitWarning: EDA signal is sampled at very low frequency. Skipping filtering.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\epochs\\eventrelated_utils.py:37: NeuroKitWarning: eda_eventrelated(): The duration of your epochs seems quite long. You might want to use eda_intervalrelated().\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\eda\\eda_clean.py:105: NeuroKitWarning: EDA signal is sampled at very low frequency. Skipping filtering.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\epochs\\eventrelated_utils.py:37: NeuroKitWarning: eda_eventrelated(): The duration of your epochs seems quite long. You might want to use eda_intervalrelated().\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\hrv\\hrv_nonlinear.py:529: NeuroKitWarning: DFA_alpha2 related indices will not be calculated. The maximum duration of the windows provided for the long-term correlation is smaller than the minimum duration of windows. Refer to the `scale` argument in `nk.fractal_dfa()` for more information.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\eda\\eda_clean.py:105: NeuroKitWarning: EDA signal is sampled at very low frequency. Skipping filtering.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\epochs\\eventrelated_utils.py:37: NeuroKitWarning: eda_eventrelated(): The duration of your epochs seems quite long. You might want to use eda_intervalrelated().\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\eda\\eda_clean.py:105: NeuroKitWarning: EDA signal is sampled at very low frequency. Skipping filtering.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\epochs\\eventrelated_utils.py:37: NeuroKitWarning: eda_eventrelated(): The duration of your epochs seems quite long. You might want to use eda_intervalrelated().\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\hrv\\hrv_nonlinear.py:529: NeuroKitWarning: DFA_alpha2 related indices will not be calculated. The maximum duration of the windows provided for the long-term correlation is smaller than the minimum duration of windows. Refer to the `scale` argument in `nk.fractal_dfa()` for more information.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\complexity\\entropy_multiscale.py:349: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  mse = np.trapz(mse) / len(mse)\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\complexity\\entropy_multiscale.py:349: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  mse = np.trapz(mse) / len(mse)\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\complexity\\entropy_multiscale.py:349: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  mse = np.trapz(mse) / len(mse)\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\eda\\eda_clean.py:105: NeuroKitWarning: EDA signal is sampled at very low frequency. Skipping filtering.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\epochs\\eventrelated_utils.py:37: NeuroKitWarning: eda_eventrelated(): The duration of your epochs seems quite long. You might want to use eda_intervalrelated().\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\eda\\eda_clean.py:105: NeuroKitWarning: EDA signal is sampled at very low frequency. Skipping filtering.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\epochs\\eventrelated_utils.py:37: NeuroKitWarning: eda_eventrelated(): The duration of your epochs seems quite long. You might want to use eda_intervalrelated().\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\hrv\\hrv_nonlinear.py:529: NeuroKitWarning: DFA_alpha2 related indices will not be calculated. The maximum duration of the windows provided for the long-term correlation is smaller than the minimum duration of windows. Refer to the `scale` argument in `nk.fractal_dfa()` for more information.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\eda\\eda_clean.py:105: NeuroKitWarning: EDA signal is sampled at very low frequency. Skipping filtering.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\epochs\\eventrelated_utils.py:37: NeuroKitWarning: eda_eventrelated(): The duration of your epochs seems quite long. You might want to use eda_intervalrelated().\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\eda\\eda_clean.py:105: NeuroKitWarning: EDA signal is sampled at very low frequency. Skipping filtering.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\epochs\\eventrelated_utils.py:37: NeuroKitWarning: eda_eventrelated(): The duration of your epochs seems quite long. You might want to use eda_intervalrelated().\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\hrv\\hrv_nonlinear.py:529: NeuroKitWarning: DFA_alpha2 related indices will not be calculated. The maximum duration of the windows provided for the long-term correlation is smaller than the minimum duration of windows. Refer to the `scale` argument in `nk.fractal_dfa()` for more information.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\eda\\eda_clean.py:105: NeuroKitWarning: EDA signal is sampled at very low frequency. Skipping filtering.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\epochs\\eventrelated_utils.py:37: NeuroKitWarning: eda_eventrelated(): The duration of your epochs seems quite long. You might want to use eda_intervalrelated().\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\eda\\eda_clean.py:105: NeuroKitWarning: EDA signal is sampled at very low frequency. Skipping filtering.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\epochs\\eventrelated_utils.py:37: NeuroKitWarning: eda_eventrelated(): The duration of your epochs seems quite long. You might want to use eda_intervalrelated().\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\hrv\\hrv_nonlinear.py:529: NeuroKitWarning: DFA_alpha2 related indices will not be calculated. The maximum duration of the windows provided for the long-term correlation is smaller than the minimum duration of windows. Refer to the `scale` argument in `nk.fractal_dfa()` for more information.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\eda\\eda_clean.py:105: NeuroKitWarning: EDA signal is sampled at very low frequency. Skipping filtering.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\epochs\\eventrelated_utils.py:37: NeuroKitWarning: eda_eventrelated(): The duration of your epochs seems quite long. You might want to use eda_intervalrelated().\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\eda\\eda_clean.py:105: NeuroKitWarning: EDA signal is sampled at very low frequency. Skipping filtering.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\epochs\\eventrelated_utils.py:37: NeuroKitWarning: eda_eventrelated(): The duration of your epochs seems quite long. You might want to use eda_intervalrelated().\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\hrv\\hrv_nonlinear.py:529: NeuroKitWarning: DFA_alpha2 related indices will not be calculated. The maximum duration of the windows provided for the long-term correlation is smaller than the minimum duration of windows. Refer to the `scale` argument in `nk.fractal_dfa()` for more information.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\eda\\eda_clean.py:105: NeuroKitWarning: EDA signal is sampled at very low frequency. Skipping filtering.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\epochs\\eventrelated_utils.py:37: NeuroKitWarning: eda_eventrelated(): The duration of your epochs seems quite long. You might want to use eda_intervalrelated().\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\eda\\eda_clean.py:105: NeuroKitWarning: EDA signal is sampled at very low frequency. Skipping filtering.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\epochs\\eventrelated_utils.py:37: NeuroKitWarning: eda_eventrelated(): The duration of your epochs seems quite long. You might want to use eda_intervalrelated().\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\hrv\\hrv_nonlinear.py:529: NeuroKitWarning: DFA_alpha2 related indices will not be calculated. The maximum duration of the windows provided for the long-term correlation is smaller than the minimum duration of windows. Refer to the `scale` argument in `nk.fractal_dfa()` for more information.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\complexity\\entropy_multiscale.py:349: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  mse = np.trapz(mse) / len(mse)\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\complexity\\entropy_multiscale.py:349: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  mse = np.trapz(mse) / len(mse)\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\complexity\\entropy_multiscale.py:349: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  mse = np.trapz(mse) / len(mse)\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\eda\\eda_clean.py:105: NeuroKitWarning: EDA signal is sampled at very low frequency. Skipping filtering.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\epochs\\eventrelated_utils.py:37: NeuroKitWarning: eda_eventrelated(): The duration of your epochs seems quite long. You might want to use eda_intervalrelated().\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\eda\\eda_clean.py:105: NeuroKitWarning: EDA signal is sampled at very low frequency. Skipping filtering.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\epochs\\eventrelated_utils.py:37: NeuroKitWarning: eda_eventrelated(): The duration of your epochs seems quite long. You might want to use eda_intervalrelated().\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\hrv\\hrv_nonlinear.py:529: NeuroKitWarning: DFA_alpha2 related indices will not be calculated. The maximum duration of the windows provided for the long-term correlation is smaller than the minimum duration of windows. Refer to the `scale` argument in `nk.fractal_dfa()` for more information.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\complexity\\entropy_multiscale.py:349: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  mse = np.trapz(mse) / len(mse)\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\complexity\\entropy_multiscale.py:349: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  mse = np.trapz(mse) / len(mse)\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\complexity\\entropy_multiscale.py:349: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  mse = np.trapz(mse) / len(mse)\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\eda\\eda_clean.py:105: NeuroKitWarning: EDA signal is sampled at very low frequency. Skipping filtering.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\epochs\\eventrelated_utils.py:37: NeuroKitWarning: eda_eventrelated(): The duration of your epochs seems quite long. You might want to use eda_intervalrelated().\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\eda\\eda_clean.py:105: NeuroKitWarning: EDA signal is sampled at very low frequency. Skipping filtering.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\epochs\\eventrelated_utils.py:37: NeuroKitWarning: eda_eventrelated(): The duration of your epochs seems quite long. You might want to use eda_intervalrelated().\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\hrv\\hrv_nonlinear.py:529: NeuroKitWarning: DFA_alpha2 related indices will not be calculated. The maximum duration of the windows provided for the long-term correlation is smaller than the minimum duration of windows. Refer to the `scale` argument in `nk.fractal_dfa()` for more information.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\eda\\eda_clean.py:105: NeuroKitWarning: EDA signal is sampled at very low frequency. Skipping filtering.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\epochs\\eventrelated_utils.py:37: NeuroKitWarning: eda_eventrelated(): The duration of your epochs seems quite long. You might want to use eda_intervalrelated().\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\eda\\eda_clean.py:105: NeuroKitWarning: EDA signal is sampled at very low frequency. Skipping filtering.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\epochs\\eventrelated_utils.py:37: NeuroKitWarning: eda_eventrelated(): The duration of your epochs seems quite long. You might want to use eda_intervalrelated().\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\hrv\\hrv_nonlinear.py:529: NeuroKitWarning: DFA_alpha2 related indices will not be calculated. The maximum duration of the windows provided for the long-term correlation is smaller than the minimum duration of windows. Refer to the `scale` argument in `nk.fractal_dfa()` for more information.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\eda\\eda_clean.py:105: NeuroKitWarning: EDA signal is sampled at very low frequency. Skipping filtering.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\epochs\\eventrelated_utils.py:37: NeuroKitWarning: eda_eventrelated(): The duration of your epochs seems quite long. You might want to use eda_intervalrelated().\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\eda\\eda_clean.py:105: NeuroKitWarning: EDA signal is sampled at very low frequency. Skipping filtering.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\epochs\\eventrelated_utils.py:37: NeuroKitWarning: eda_eventrelated(): The duration of your epochs seems quite long. You might want to use eda_intervalrelated().\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\hrv\\hrv_nonlinear.py:529: NeuroKitWarning: DFA_alpha2 related indices will not be calculated. The maximum duration of the windows provided for the long-term correlation is smaller than the minimum duration of windows. Refer to the `scale` argument in `nk.fractal_dfa()` for more information.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\eda\\eda_clean.py:105: NeuroKitWarning: EDA signal is sampled at very low frequency. Skipping filtering.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\epochs\\eventrelated_utils.py:37: NeuroKitWarning: eda_eventrelated(): The duration of your epochs seems quite long. You might want to use eda_intervalrelated().\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\eda\\eda_clean.py:105: NeuroKitWarning: EDA signal is sampled at very low frequency. Skipping filtering.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\epochs\\eventrelated_utils.py:37: NeuroKitWarning: eda_eventrelated(): The duration of your epochs seems quite long. You might want to use eda_intervalrelated().\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\hrv\\hrv_nonlinear.py:529: NeuroKitWarning: DFA_alpha2 related indices will not be calculated. The maximum duration of the windows provided for the long-term correlation is smaller than the minimum duration of windows. Refer to the `scale` argument in `nk.fractal_dfa()` for more information.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\eda\\eda_clean.py:105: NeuroKitWarning: EDA signal is sampled at very low frequency. Skipping filtering.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\epochs\\eventrelated_utils.py:37: NeuroKitWarning: eda_eventrelated(): The duration of your epochs seems quite long. You might want to use eda_intervalrelated().\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\eda\\eda_clean.py:105: NeuroKitWarning: EDA signal is sampled at very low frequency. Skipping filtering.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\epochs\\eventrelated_utils.py:37: NeuroKitWarning: eda_eventrelated(): The duration of your epochs seems quite long. You might want to use eda_intervalrelated().\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\hrv\\hrv_nonlinear.py:529: NeuroKitWarning: DFA_alpha2 related indices will not be calculated. The maximum duration of the windows provided for the long-term correlation is smaller than the minimum duration of windows. Refer to the `scale` argument in `nk.fractal_dfa()` for more information.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\eda\\eda_clean.py:105: NeuroKitWarning: EDA signal is sampled at very low frequency. Skipping filtering.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\epochs\\eventrelated_utils.py:37: NeuroKitWarning: eda_eventrelated(): The duration of your epochs seems quite long. You might want to use eda_intervalrelated().\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\eda\\eda_clean.py:105: NeuroKitWarning: EDA signal is sampled at very low frequency. Skipping filtering.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\epochs\\eventrelated_utils.py:37: NeuroKitWarning: eda_eventrelated(): The duration of your epochs seems quite long. You might want to use eda_intervalrelated().\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\hrv\\hrv_nonlinear.py:529: NeuroKitWarning: DFA_alpha2 related indices will not be calculated. The maximum duration of the windows provided for the long-term correlation is smaller than the minimum duration of windows. Refer to the `scale` argument in `nk.fractal_dfa()` for more information.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\complexity\\entropy_multiscale.py:349: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  mse = np.trapz(mse) / len(mse)\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\complexity\\entropy_multiscale.py:349: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  mse = np.trapz(mse) / len(mse)\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\complexity\\entropy_multiscale.py:349: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  mse = np.trapz(mse) / len(mse)\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\eda\\eda_clean.py:105: NeuroKitWarning: EDA signal is sampled at very low frequency. Skipping filtering.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\epochs\\eventrelated_utils.py:37: NeuroKitWarning: eda_eventrelated(): The duration of your epochs seems quite long. You might want to use eda_intervalrelated().\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\eda\\eda_clean.py:105: NeuroKitWarning: EDA signal is sampled at very low frequency. Skipping filtering.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\epochs\\eventrelated_utils.py:37: NeuroKitWarning: eda_eventrelated(): The duration of your epochs seems quite long. You might want to use eda_intervalrelated().\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\hrv\\hrv_nonlinear.py:529: NeuroKitWarning: DFA_alpha2 related indices will not be calculated. The maximum duration of the windows provided for the long-term correlation is smaller than the minimum duration of windows. Refer to the `scale` argument in `nk.fractal_dfa()` for more information.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\eda\\eda_clean.py:105: NeuroKitWarning: EDA signal is sampled at very low frequency. Skipping filtering.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\epochs\\eventrelated_utils.py:37: NeuroKitWarning: eda_eventrelated(): The duration of your epochs seems quite long. You might want to use eda_intervalrelated().\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\eda\\eda_clean.py:105: NeuroKitWarning: EDA signal is sampled at very low frequency. Skipping filtering.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\epochs\\eventrelated_utils.py:37: NeuroKitWarning: eda_eventrelated(): The duration of your epochs seems quite long. You might want to use eda_intervalrelated().\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\hrv\\hrv_nonlinear.py:529: NeuroKitWarning: DFA_alpha2 related indices will not be calculated. The maximum duration of the windows provided for the long-term correlation is smaller than the minimum duration of windows. Refer to the `scale` argument in `nk.fractal_dfa()` for more information.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\eda\\eda_clean.py:105: NeuroKitWarning: EDA signal is sampled at very low frequency. Skipping filtering.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\epochs\\eventrelated_utils.py:37: NeuroKitWarning: eda_eventrelated(): The duration of your epochs seems quite long. You might want to use eda_intervalrelated().\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\eda\\eda_clean.py:105: NeuroKitWarning: EDA signal is sampled at very low frequency. Skipping filtering.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\epochs\\eventrelated_utils.py:37: NeuroKitWarning: eda_eventrelated(): The duration of your epochs seems quite long. You might want to use eda_intervalrelated().\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\hrv\\hrv_nonlinear.py:529: NeuroKitWarning: DFA_alpha2 related indices will not be calculated. The maximum duration of the windows provided for the long-term correlation is smaller than the minimum duration of windows. Refer to the `scale` argument in `nk.fractal_dfa()` for more information.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\eda\\eda_clean.py:105: NeuroKitWarning: EDA signal is sampled at very low frequency. Skipping filtering.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\epochs\\eventrelated_utils.py:37: NeuroKitWarning: eda_eventrelated(): The duration of your epochs seems quite long. You might want to use eda_intervalrelated().\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\eda\\eda_clean.py:105: NeuroKitWarning: EDA signal is sampled at very low frequency. Skipping filtering.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\epochs\\eventrelated_utils.py:37: NeuroKitWarning: eda_eventrelated(): The duration of your epochs seems quite long. You might want to use eda_intervalrelated().\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\hrv\\hrv_nonlinear.py:529: NeuroKitWarning: DFA_alpha2 related indices will not be calculated. The maximum duration of the windows provided for the long-term correlation is smaller than the minimum duration of windows. Refer to the `scale` argument in `nk.fractal_dfa()` for more information.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\complexity\\entropy_multiscale.py:349: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  mse = np.trapz(mse) / len(mse)\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\complexity\\entropy_multiscale.py:349: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  mse = np.trapz(mse) / len(mse)\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\complexity\\entropy_multiscale.py:349: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  mse = np.trapz(mse) / len(mse)\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\eda\\eda_clean.py:105: NeuroKitWarning: EDA signal is sampled at very low frequency. Skipping filtering.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\epochs\\eventrelated_utils.py:37: NeuroKitWarning: eda_eventrelated(): The duration of your epochs seems quite long. You might want to use eda_intervalrelated().\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\eda\\eda_clean.py:105: NeuroKitWarning: EDA signal is sampled at very low frequency. Skipping filtering.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\epochs\\eventrelated_utils.py:37: NeuroKitWarning: eda_eventrelated(): The duration of your epochs seems quite long. You might want to use eda_intervalrelated().\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\hrv\\hrv_nonlinear.py:529: NeuroKitWarning: DFA_alpha2 related indices will not be calculated. The maximum duration of the windows provided for the long-term correlation is smaller than the minimum duration of windows. Refer to the `scale` argument in `nk.fractal_dfa()` for more information.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\eda\\eda_clean.py:105: NeuroKitWarning: EDA signal is sampled at very low frequency. Skipping filtering.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\epochs\\eventrelated_utils.py:37: NeuroKitWarning: eda_eventrelated(): The duration of your epochs seems quite long. You might want to use eda_intervalrelated().\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\eda\\eda_clean.py:105: NeuroKitWarning: EDA signal is sampled at very low frequency. Skipping filtering.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\epochs\\eventrelated_utils.py:37: NeuroKitWarning: eda_eventrelated(): The duration of your epochs seems quite long. You might want to use eda_intervalrelated().\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\hrv\\hrv_nonlinear.py:529: NeuroKitWarning: DFA_alpha2 related indices will not be calculated. The maximum duration of the windows provided for the long-term correlation is smaller than the minimum duration of windows. Refer to the `scale` argument in `nk.fractal_dfa()` for more information.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\eda\\eda_clean.py:105: NeuroKitWarning: EDA signal is sampled at very low frequency. Skipping filtering.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\epochs\\eventrelated_utils.py:37: NeuroKitWarning: eda_eventrelated(): The duration of your epochs seems quite long. You might want to use eda_intervalrelated().\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\eda\\eda_clean.py:105: NeuroKitWarning: EDA signal is sampled at very low frequency. Skipping filtering.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\epochs\\eventrelated_utils.py:37: NeuroKitWarning: eda_eventrelated(): The duration of your epochs seems quite long. You might want to use eda_intervalrelated().\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\hrv\\hrv_nonlinear.py:529: NeuroKitWarning: DFA_alpha2 related indices will not be calculated. The maximum duration of the windows provided for the long-term correlation is smaller than the minimum duration of windows. Refer to the `scale` argument in `nk.fractal_dfa()` for more information.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\complexity\\entropy_multiscale.py:349: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  mse = np.trapz(mse) / len(mse)\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\complexity\\entropy_multiscale.py:349: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  mse = np.trapz(mse) / len(mse)\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\complexity\\entropy_multiscale.py:349: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  mse = np.trapz(mse) / len(mse)\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\eda\\eda_clean.py:105: NeuroKitWarning: EDA signal is sampled at very low frequency. Skipping filtering.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\epochs\\eventrelated_utils.py:37: NeuroKitWarning: eda_eventrelated(): The duration of your epochs seems quite long. You might want to use eda_intervalrelated().\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\eda\\eda_clean.py:105: NeuroKitWarning: EDA signal is sampled at very low frequency. Skipping filtering.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\epochs\\eventrelated_utils.py:37: NeuroKitWarning: eda_eventrelated(): The duration of your epochs seems quite long. You might want to use eda_intervalrelated().\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\hrv\\hrv_nonlinear.py:529: NeuroKitWarning: DFA_alpha2 related indices will not be calculated. The maximum duration of the windows provided for the long-term correlation is smaller than the minimum duration of windows. Refer to the `scale` argument in `nk.fractal_dfa()` for more information.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\complexity\\entropy_multiscale.py:349: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  mse = np.trapz(mse) / len(mse)\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\complexity\\entropy_multiscale.py:349: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  mse = np.trapz(mse) / len(mse)\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\complexity\\entropy_multiscale.py:349: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  mse = np.trapz(mse) / len(mse)\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\eda\\eda_clean.py:105: NeuroKitWarning: EDA signal is sampled at very low frequency. Skipping filtering.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\epochs\\eventrelated_utils.py:37: NeuroKitWarning: eda_eventrelated(): The duration of your epochs seems quite long. You might want to use eda_intervalrelated().\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\eda\\eda_clean.py:105: NeuroKitWarning: EDA signal is sampled at very low frequency. Skipping filtering.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\epochs\\eventrelated_utils.py:37: NeuroKitWarning: eda_eventrelated(): The duration of your epochs seems quite long. You might want to use eda_intervalrelated().\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\hrv\\hrv_nonlinear.py:529: NeuroKitWarning: DFA_alpha2 related indices will not be calculated. The maximum duration of the windows provided for the long-term correlation is smaller than the minimum duration of windows. Refer to the `scale` argument in `nk.fractal_dfa()` for more information.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\complexity\\entropy_multiscale.py:349: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  mse = np.trapz(mse) / len(mse)\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\complexity\\entropy_multiscale.py:349: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  mse = np.trapz(mse) / len(mse)\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\complexity\\entropy_multiscale.py:349: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  mse = np.trapz(mse) / len(mse)\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\eda\\eda_clean.py:105: NeuroKitWarning: EDA signal is sampled at very low frequency. Skipping filtering.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\epochs\\eventrelated_utils.py:37: NeuroKitWarning: eda_eventrelated(): The duration of your epochs seems quite long. You might want to use eda_intervalrelated().\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\eda\\eda_clean.py:105: NeuroKitWarning: EDA signal is sampled at very low frequency. Skipping filtering.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\epochs\\eventrelated_utils.py:37: NeuroKitWarning: eda_eventrelated(): The duration of your epochs seems quite long. You might want to use eda_intervalrelated().\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\hrv\\hrv_nonlinear.py:529: NeuroKitWarning: DFA_alpha2 related indices will not be calculated. The maximum duration of the windows provided for the long-term correlation is smaller than the minimum duration of windows. Refer to the `scale` argument in `nk.fractal_dfa()` for more information.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\complexity\\entropy_multiscale.py:349: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  mse = np.trapz(mse) / len(mse)\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\complexity\\entropy_multiscale.py:349: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  mse = np.trapz(mse) / len(mse)\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\complexity\\entropy_multiscale.py:349: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  mse = np.trapz(mse) / len(mse)\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\eda\\eda_clean.py:105: NeuroKitWarning: EDA signal is sampled at very low frequency. Skipping filtering.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\epochs\\eventrelated_utils.py:37: NeuroKitWarning: eda_eventrelated(): The duration of your epochs seems quite long. You might want to use eda_intervalrelated().\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\eda\\eda_clean.py:105: NeuroKitWarning: EDA signal is sampled at very low frequency. Skipping filtering.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\epochs\\eventrelated_utils.py:37: NeuroKitWarning: eda_eventrelated(): The duration of your epochs seems quite long. You might want to use eda_intervalrelated().\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\hrv\\hrv_nonlinear.py:529: NeuroKitWarning: DFA_alpha2 related indices will not be calculated. The maximum duration of the windows provided for the long-term correlation is smaller than the minimum duration of windows. Refer to the `scale` argument in `nk.fractal_dfa()` for more information.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\eda\\eda_clean.py:105: NeuroKitWarning: EDA signal is sampled at very low frequency. Skipping filtering.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\epochs\\eventrelated_utils.py:37: NeuroKitWarning: eda_eventrelated(): The duration of your epochs seems quite long. You might want to use eda_intervalrelated().\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\eda\\eda_clean.py:105: NeuroKitWarning: EDA signal is sampled at very low frequency. Skipping filtering.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\epochs\\eventrelated_utils.py:37: NeuroKitWarning: eda_eventrelated(): The duration of your epochs seems quite long. You might want to use eda_intervalrelated().\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\hrv\\hrv_nonlinear.py:529: NeuroKitWarning: DFA_alpha2 related indices will not be calculated. The maximum duration of the windows provided for the long-term correlation is smaller than the minimum duration of windows. Refer to the `scale` argument in `nk.fractal_dfa()` for more information.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\eda\\eda_clean.py:105: NeuroKitWarning: EDA signal is sampled at very low frequency. Skipping filtering.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\epochs\\eventrelated_utils.py:37: NeuroKitWarning: eda_eventrelated(): The duration of your epochs seems quite long. You might want to use eda_intervalrelated().\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\eda\\eda_clean.py:105: NeuroKitWarning: EDA signal is sampled at very low frequency. Skipping filtering.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\epochs\\eventrelated_utils.py:37: NeuroKitWarning: eda_eventrelated(): The duration of your epochs seems quite long. You might want to use eda_intervalrelated().\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\hrv\\hrv_nonlinear.py:529: NeuroKitWarning: DFA_alpha2 related indices will not be calculated. The maximum duration of the windows provided for the long-term correlation is smaller than the minimum duration of windows. Refer to the `scale` argument in `nk.fractal_dfa()` for more information.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\eda\\eda_clean.py:105: NeuroKitWarning: EDA signal is sampled at very low frequency. Skipping filtering.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\epochs\\eventrelated_utils.py:37: NeuroKitWarning: eda_eventrelated(): The duration of your epochs seems quite long. You might want to use eda_intervalrelated().\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\eda\\eda_clean.py:105: NeuroKitWarning: EDA signal is sampled at very low frequency. Skipping filtering.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\epochs\\eventrelated_utils.py:37: NeuroKitWarning: eda_eventrelated(): The duration of your epochs seems quite long. You might want to use eda_intervalrelated().\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\hrv\\hrv_nonlinear.py:529: NeuroKitWarning: DFA_alpha2 related indices will not be calculated. The maximum duration of the windows provided for the long-term correlation is smaller than the minimum duration of windows. Refer to the `scale` argument in `nk.fractal_dfa()` for more information.\n",
      "  warn(\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\complexity\\entropy_multiscale.py:349: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  mse = np.trapz(mse) / len(mse)\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\complexity\\entropy_multiscale.py:349: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  mse = np.trapz(mse) / len(mse)\n",
      "c:\\Users\\Mario Tokumori\\.conda\\envs\\handeln2025\\lib\\site-packages\\neurokit2\\complexity\\entropy_multiscale.py:349: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  mse = np.trapz(mse) / len(mse)\n"
     ]
    }
   ],
   "source": [
    "X = extract_features(ibi_segments, eda_segments, skt_segments)\n",
    "X = pd.DataFrame(X)\n",
    "\n",
    "# Some features are only defined for segments of certain minimal lengths\n",
    "# X could contain NaN values in columns like SampEn (1 value from 54)\n",
    "X = X.replace([np.inf, -np.inf], np.nan)\n",
    "X = X.drop(columns=X.columns[X.isna().all()])\n",
    "\n",
    "preprocessor = Pipeline(steps=[\n",
    "    ('impute', SimpleImputer(strategy='most_frequent')),\n",
    "    ('remove_constant', VarianceThreshold())\n",
    "])\n",
    "preprocessor.set_output(transform=\"pandas\")\n",
    "X_processed = preprocessor.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085ce007",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Selects the optimal number of features based on Leave-One-Out cross-validation, \n",
    "### Ideal for small datasets to prevent overfitting\n",
    "rfecv_with_forest = RFECV(RandomForestClassifier(), step=1, cv=LeaveOneOut(), n_jobs=-1).fit(X_processed, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "54ee043d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- SVM ---\n",
      "Best Score: 0.5741\n",
      "Best Params: {'svm__C': 0.1, 'svm__kernel': 'linear'}\n",
      "\n",
      "--- K-Nearest Neighbors ---\n",
      "Best Score: 0.4074\n",
      "Best Params: {'knn__n_neighbors': 5}\n",
      "\n",
      "--- Gaussian Naive Bayes ---\n",
      "Best Score: 0.4444\n",
      "Label mapping (String -> Number):\n",
      "{'Anger': 0, 'Happiness': 1, 'Sadness': 2}\n",
      "\n",
      "--- Neural Network (Warning: High Overfit Risk) ---\n",
      "Best Score: 0.4444\n",
      "Best Params: {'nn__hidden_layer_sizes': (10, 5)}\n",
      "\n",
      "--- Random Forest ---\n",
      "Best Score: 0.5741\n",
      "Best Params: {'rf__max_depth': None, 'rf__n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# We create pipelines to test everything properly\n",
    "# We *must* scale data for SVM, KNN, and NN.\n",
    "# GaussianNB should NOT be scaled, as it expects Gaussian-distributed data.\n",
    "\n",
    "# --- 1. SVM Tuning ---\n",
    "pipe_svm = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('svm', SVC(random_state=42))\n",
    "])\n",
    "# We tune 'C' (regularization) and 'kernel'\n",
    "param_svm = {\n",
    "    'svm__C': [0.1, 1, 10],\n",
    "    'svm__kernel': ['linear', 'rbf']\n",
    "}\n",
    "grid_svm = GridSearchCV(pipe_svm, param_svm, cv=LeaveOneOut(), scoring='accuracy', n_jobs=-1)\n",
    "grid_svm.fit(X_processed, y)\n",
    "print(f\"\\n--- SVM ---\")\n",
    "print(f\"Best Score: {grid_svm.best_score_:.4f}\")\n",
    "print(f\"Best Params: {grid_svm.best_params_}\")\n",
    "\n",
    "# --- 2. KNN Tuning ---\n",
    "pipe_knn = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('knn', KNeighborsClassifier())\n",
    "])\n",
    "# We tune 'n_neighbors' (the 'k' value)\n",
    "param_knn = {\n",
    "    'knn__n_neighbors': [3, 5, 7, 9] # Small, odd numbers\n",
    "}\n",
    "grid_knn = GridSearchCV(pipe_knn, param_knn, cv=LeaveOneOut(), scoring='accuracy', n_jobs=-1)\n",
    "grid_knn.fit(X_processed, y)\n",
    "print(f\"\\n--- K-Nearest Neighbors ---\")\n",
    "print(f\"Best Score: {grid_knn.best_score_:.4f}\")\n",
    "print(f\"Best Params: {grid_knn.best_params_}\")\n",
    "\n",
    "# --- 3. Gaussian Naive Bayes (No Tuning) ---\n",
    "# This model has no real hyperparameters, so we just get its score\n",
    "pipe_gnb = Pipeline([\n",
    "    # No scaling!\n",
    "    ('gnb', GaussianNB())\n",
    "])\n",
    "grid_gnb = GridSearchCV(pipe_gnb, {}, cv=LeaveOneOut(), scoring='accuracy', n_jobs=-1) # Empty param grid\n",
    "grid_gnb.fit(X_processed, y)\n",
    "print(f\"\\n--- Gaussian Naive Bayes ---\")\n",
    "print(f\"Best Score: {grid_gnb.best_score_:.4f}\")\n",
    "\n",
    "\n",
    "# --- 4. Neural Network (WARNING) ---\n",
    "# This is *very* likely to overfit, but here is how you'd do it.\n",
    "# We test a *tiny* network.\n",
    "\n",
    "# --- Encode your labels ---\n",
    "le = LabelEncoder()\n",
    "# This converts ['Happiness', 'Anger', 'Sadness'] into [1, 0, 2]\n",
    "y_numeric = le.fit_transform(y)\n",
    "\n",
    "print(\"Label mapping (String -> Number):\")\n",
    "print(dict(zip(le.classes_, le.transform(le.classes_))))\n",
    "\n",
    "pipe_nn = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('nn', MLPClassifier(max_iter=1000, early_stopping=True, random_state=42))\n",
    "])\n",
    "# We tune the size of the single hidden layer\n",
    "param_nn = {\n",
    "    'nn__hidden_layer_sizes': [(10,), (20,), (10, 5)] # (10,) = one layer of 10 neurons\n",
    "}\n",
    "grid_nn = GridSearchCV(pipe_nn, param_nn, cv=LeaveOneOut(), scoring='accuracy', n_jobs=-1)\n",
    "grid_nn.fit(X_processed, y_numeric)\n",
    "print(f\"\\n--- Neural Network (Warning: High Overfit Risk) ---\")\n",
    "print(f\"Best Score: {grid_nn.best_score_:.4f}\")\n",
    "print(f\"Best Params: {grid_nn.best_params_}\")\n",
    "\n",
    "\n",
    "# --- 5. RandomForest (Tuning) ---\n",
    "# We can tune this too, for a fair comparison\n",
    "pipe_rf = Pipeline([\n",
    "    # No scaling needed\n",
    "    ('rf', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "param_rf = {\n",
    "    'rf__n_estimators': [50, 100],\n",
    "    'rf__max_depth': [3, 5, None]\n",
    "}\n",
    "grid_rf = GridSearchCV(pipe_rf, param_rf, cv=LeaveOneOut(), scoring='accuracy', n_jobs=-1)\n",
    "grid_rf.fit(X_processed, y)\n",
    "print(f\"\\n--- Random Forest ---\")\n",
    "print(f\"Best Score: {grid_rf.best_score_:.4f}\")\n",
    "print(f\"Best Params: {grid_rf.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "77c8df23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running RFECV with RandomForest...\n",
      "Optimal features for RF: 1\n",
      "Running RFECV with Linear SVM...\n",
      "Optimal features for SVM: 1\n",
      "Running RFECV with Logistic Regression...\n",
      "Optimal features for LogReg: 4\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Define the cross-validation strategy\n",
    "loocv = LeaveOneOut()\n",
    "\n",
    "def get_svm_importances(fitted_estimator):\n",
    "    \"\"\"\n",
    "    Returns a 1D array of importances from a fitted SVM\n",
    "    by taking the L2 norm (Euclidean distance) of the coefficients\n",
    "    across the classes.\n",
    "    \"\"\"\n",
    "    # 1. Access the fitted SVC model from the pipeline\n",
    "    svm_model = fitted_estimator.named_steps['svm']\n",
    "    \n",
    "    # 2. Get the 2D coefficient matrix (shape [n_classes, n_features])\n",
    "    coefs = svm_model.coef_\n",
    "    \n",
    "    # 3. Calculate the L2 norm across the class rows (axis=0)\n",
    "    # This results in a 1D array of shape [n_features]\n",
    "    importances = np.linalg.norm(coefs, axis=0)\n",
    "    \n",
    "    return importances\n",
    "\n",
    "def get_lr_importances(fitted_estimator):\n",
    "    \"\"\"\n",
    "    Returns a 1D array of importances from a fitted LogisticRegression\n",
    "    by taking the L2 norm (Euclidean distance) of the coefficients\n",
    "    across the classes.\n",
    "    \"\"\"\n",
    "    # 1. Access the fitted LogisticRegression model from the pipeline\n",
    "    lr_model = fitted_estimator.named_steps['lr'] # <-- Accesses the 'lr' step\n",
    "    \n",
    "    # 2. Get the 2D coefficient matrix (shape [n_classes, n_features])\n",
    "    coefs = lr_model.coef_\n",
    "    \n",
    "    # 3. Calculate the L2 norm across the class rows (axis=0)\n",
    "    importances = np.linalg.norm(coefs, axis=0)\n",
    "    \n",
    "    return importances\n",
    "\n",
    "# --- 1. RandomForest (Your Original) ---\n",
    "print(\"Running RFECV with RandomForest...\")\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rfecv_rf = RFECV(estimator=rf_model, step=1, cv=loocv, scoring='accuracy', n_jobs=-1)\n",
    "rfecv_rf.fit(X_processed, y)\n",
    "\n",
    "print(f\"Optimal features for RF: {rfecv_rf.n_features_}\")\n",
    "\n",
    "# --- 2. SVM (Must be Linear) ---\n",
    "# Non-linear kernels (like 'rbf') do not have a .coef_ attribute\n",
    "# We use a Pipeline to scale data *inside* the CV loop, which is best practice.\n",
    "print(\"Running RFECV with Linear SVM...\")\n",
    "svc_pipeline = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('svm', SVC(kernel='linear', C=1, random_state=42)) \n",
    "])\n",
    "\n",
    "rfecv_svm = RFECV(\n",
    "    estimator=svc_pipeline, \n",
    "    step=1, \n",
    "    cv=loocv, \n",
    "    scoring='accuracy', \n",
    "    n_jobs=-1,\n",
    "    importance_getter=get_svm_importances \n",
    ")\n",
    "rfecv_svm.fit(X_processed, y)\n",
    "print(f\"Optimal features for SVM: {rfecv_svm.n_features_}\")\n",
    "\n",
    "# --- 3. Logistic Regression (as a simple/stable NN) ---\n",
    "print(\"Running RFECV with Logistic Regression...\")\n",
    "lr_pipeline = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('lr', LogisticRegression(multi_class='ovr', solver='liblinear', random_state=42))\n",
    "])\n",
    "rfecv_lr = RFECV(\n",
    "    estimator=lr_pipeline, \n",
    "    step=1, \n",
    "    cv=loocv, \n",
    "    scoring='accuracy', \n",
    "    n_jobs=-1,\n",
    "    importance_getter=get_lr_importances \n",
    ")\n",
    "rfecv_lr.fit(X_processed, y)\n",
    "\n",
    "print(f\"Optimal features for LogReg: {rfecv_lr.n_features_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "a9b64ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "classifiers = pickle.load(open(r'C:\\Users\\Mario Tokumori\\Documents\\TUDarmstadt\\6. Semester\\Thesis\\Alexithymia\\classifiers_.pkl', 'rb' ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "32456910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---  Results for Participant 1 ---\n",
      "\n",
      "  Condition: audio+image\n",
      "  ===================================\n",
      "     grid_svm:\n",
      "        Best Score:  0.6111\n",
      "        Best Params: {'svm__C': 10, 'svm__kernel': 'rbf'}\n",
      "     grid_knn:\n",
      "        Best Score:  0.5741\n",
      "        Best Params: {'knn__n_neighbors': 3}\n",
      "     grid_gnb:\n",
      "        Best Score:  0.6667\n",
      "        Best Params: {}\n",
      "     label_encoder:\n",
      "        Mapping: {'Anger': 0, 'Happiness': 1, 'Sadness': 2}\n",
      "     grid_nn:\n",
      "        Best Score:  0.3333\n",
      "        Best Params: {'nn__hidden_layer_sizes': (10, 5)}\n",
      "     grid_rf:\n",
      "        Best Score:  0.7037\n",
      "        Best Params: {'rf__max_depth': 3, 'rf__n_estimators': 100}\n",
      "     rfecv_rf:\n",
      "        Optimal Features: 33\n",
      "        Score at 33 features: 0.7222\n",
      "     rfecv_svm:\n",
      "        Optimal Features: 16\n",
      "        Score at 16 features: 0.5741\n",
      "     rfecv_lr:\n",
      "        Optimal Features: 31\n",
      "        Score at 31 features: 0.6296\n",
      "\n",
      "  Condition: image-only\n",
      "  ===================================\n",
      "     grid_svm:\n",
      "        Best Score:  0.6296\n",
      "        Best Params: {'svm__C': 1, 'svm__kernel': 'linear'}\n",
      "     grid_knn:\n",
      "        Best Score:  0.5556\n",
      "        Best Params: {'knn__n_neighbors': 3}\n",
      "     grid_gnb:\n",
      "        Best Score:  0.4815\n",
      "        Best Params: {}\n",
      "     label_encoder:\n",
      "        Mapping: {'Anger': 0, 'Happiness': 1, 'Sadness': 2}\n",
      "     grid_nn:\n",
      "        Best Score:  0.4074\n",
      "        Best Params: {'nn__hidden_layer_sizes': (10,)}\n",
      "     grid_rf:\n",
      "        Best Score:  0.6111\n",
      "        Best Params: {'rf__max_depth': 5, 'rf__n_estimators': 100}\n",
      "     rfecv_rf:\n",
      "        Optimal Features: 42\n",
      "        Score at 42 features: 0.6296\n",
      "     rfecv_svm:\n",
      "        Optimal Features: 13\n",
      "        Score at 13 features: 0.6852\n",
      "     rfecv_lr:\n",
      "        Optimal Features: 15\n",
      "        Score at 15 features: 0.6667\n",
      "\n",
      "  Condition: audio-only\n",
      "  ===================================\n",
      "     grid_svm:\n",
      "        Best Score:  0.7222\n",
      "        Best Params: {'svm__C': 10, 'svm__kernel': 'rbf'}\n",
      "     grid_knn:\n",
      "        Best Score:  0.5556\n",
      "        Best Params: {'knn__n_neighbors': 5}\n",
      "     grid_gnb:\n",
      "        Best Score:  0.6481\n",
      "        Best Params: {}\n",
      "     label_encoder:\n",
      "        Mapping: {'Anger': 0, 'Happiness': 1, 'Sadness': 2}\n",
      "     grid_nn:\n",
      "        Best Score:  0.3519\n",
      "        Best Params: {'nn__hidden_layer_sizes': (10, 5)}\n",
      "     grid_rf:\n",
      "        Best Score:  0.6111\n",
      "        Best Params: {'rf__max_depth': 5, 'rf__n_estimators': 100}\n",
      "     rfecv_rf:\n",
      "        Optimal Features: 8\n",
      "        Score at 8 features: 0.7778\n",
      "     rfecv_svm:\n",
      "        Optimal Features: 9\n",
      "        Score at 9 features: 0.7222\n",
      "     rfecv_lr:\n",
      "        Optimal Features: 25\n",
      "        Score at 25 features: 0.6852\n"
     ]
    }
   ],
   "source": [
    "pid_to_print = 1\n",
    "\n",
    "# --- Check if participant data exists ---\n",
    "if pid_to_print not in classifiers:\n",
    "    print(f\"Error: Participant {pid_to_print} not found in the results.\")\n",
    "else:\n",
    "    participant_data = classifiers[pid_to_print]\n",
    "    \n",
    "    print(f\"---  Results for Participant {pid_to_print} ---\")\n",
    "    \n",
    "    # Iterate over each condition (e.g., 'audio+image')\n",
    "    for condition, models in participant_data.items():\n",
    "        print(f\"\\n  Condition: {condition}\")\n",
    "        print(\"  \" + \"=\"*35)\n",
    "        \n",
    "        # Iterate over each model entry\n",
    "        for model_name, model_obj in models.items():\n",
    "            \n",
    "            # --- Handle GridSearchCV objects ---\n",
    "            if \"grid_\" in model_name:\n",
    "                try:\n",
    "                    print(f\"     {model_name}:\")\n",
    "                    print(f\"        Best Score:  {model_obj.best_score_:.4f}\")\n",
    "                    print(f\"        Best Params: {model_obj.best_params_}\")\n",
    "                except AttributeError:\n",
    "                    print(f\"     {model_name}: (Object is not a fitted GridSearchCV)\")\n",
    "                except Exception as e:\n",
    "                    print(f\"     {model_name}: Error printing results - {e}\")\n",
    "            \n",
    "            # --- Handle RFECV objects ---\n",
    "            elif \"rfecv_\" in model_name:\n",
    "                try:\n",
    "                    print(f\"     {model_name}:\")\n",
    "                    print(f\"        Optimal Features: {model_obj.n_features_}\")\n",
    "                    \n",
    "                    # Get the score that corresponds to the optimal number of features\n",
    "                    # This assumes 'min_features_to_select=1' and 'step=1'\n",
    "                    score_index = model_obj.n_features_ - 1 \n",
    "                    best_score = model_obj.cv_results_['mean_test_score'][score_index]\n",
    "                    \n",
    "                    print(f\"        Score at {model_obj.n_features_} features: {best_score:.4f}\")\n",
    "                except AttributeError:\n",
    "                     print(f\"     {model_name}: (Object is not a fitted RFECV)\")\n",
    "                except Exception as e:\n",
    "                    print(f\"     {model_name}: Error printing results - {e}\")\n",
    "\n",
    "            # --- Handle LabelEncoder ---\n",
    "            elif model_name == 'label_encoder':\n",
    "                try:\n",
    "                    print(f\"     {model_name}:\")\n",
    "                    mapping = dict(zip(model_obj.classes_, model_obj.transform(model_obj.classes_)))\n",
    "                    print(f\"        Mapping: {mapping}\")\n",
    "                except Exception:\n",
    "                    pass # Ignore if it's not a fitted encoder\n",
    "            \n",
    "            # --- Other objects (like functions) are skipped ---\n",
    "            else:\n",
    "                pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
